{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "    start = time.time()\n",
    "    go = True\n",
    "    i = 1\n",
    "    content = []\n",
    "    while(go):\n",
    "        response = requests.get(url+str(i))\n",
    "        if \"Sorry no bots match that combination\" in response.content.decode():\n",
    "            go = False\n",
    "        else:\n",
    "            content.append(response.content)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Page no. {} downloaded\".format(i))\n",
    "        i += 1 \n",
    "    num_of_pages = i-1 \n",
    "    total_time = time.time() - start\n",
    "    return content, num_of_pages, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page no. 10 downloaded\n",
      "Page no. 20 downloaded\n",
      "Page no. 30 downloaded\n",
      "Page no. 40 downloaded\n",
      "Page no. 50 downloaded\n",
      "Page no. 60 downloaded\n",
      "Page no. 70 downloaded\n",
      "Page no. 80 downloaded\n",
      "Page no. 90 downloaded\n",
      "Page no. 100 downloaded\n",
      "Page no. 110 downloaded\n",
      "Page no. 120 downloaded\n",
      "Page no. 130 downloaded\n",
      "Page no. 140 downloaded\n",
      "Page no. 150 downloaded\n",
      "Page no. 160 downloaded\n",
      "Page no. 170 downloaded\n",
      "Page no. 180 downloaded\n",
      "Page no. 190 downloaded\n",
      "Page no. 200 downloaded\n",
      "Page no. 210 downloaded\n",
      "Page no. 220 downloaded\n",
      "Page no. 230 downloaded\n",
      "Page no. 240 downloaded\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%time content,num_pages,tot_time = get_content(\"https://botlist.co/bots/filter?category=&platform=&order=date&page=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time in seconds: -201.77960729599\n",
      "Number of downloaded pages: 249\n"
     ]
    }
   ],
   "source": [
    "print(\"Total time in seconds: {}\".format(tot_time))\n",
    "print(\"Number of downloaded pages: {}\".format(num_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content_df = pd.DataFrame(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content_df.columns = [\"html\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# page = content_df.html.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x = soup.find_all(\"div\",class_=\"bot\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x.find('a').get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x.find_all('a')[-1].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# page = content_df.html.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_urls_and_names(page):\n",
    "    lst = []\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    bots = soup.find_all(\"div\",class_=\"bot\")\n",
    "    for bot in bots:\n",
    "        sub_lst = []\n",
    "        sub_lst.append(bot.find_all('a')[0].get(\"href\"))\n",
    "        sub_lst.append(bot.find_all('a')[-1].get_text())\n",
    "        lst.append(sub_lst)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract_urls_and_names(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content_df[\"bot_data\"] = content_df[\"html\"].apply(extract_urls_and_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_names_and_urls(pages):\n",
    "    lst_total = []\n",
    "    for page in pages:\n",
    "        lst_total.append(extract_urls_and_names(page))\n",
    "    return lst_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "pages = content_df.html.values\n",
    "%time names_urls = get_names_and_urls(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_urls = sum(names_urls,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bots_df = pd.DataFrame(names_urls)\n",
    "bots_df.columns = [\"url\",\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bots_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_data(path,df):\n",
    "    df.to_json(path)\n",
    "    print(\"Output file saved to: {}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file saved to: data/bots.json\n"
     ]
    }
   ],
   "source": [
    "save_data(\"data/bots.json\",bots_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file saved to: data/raw_pages.json\n"
     ]
    }
   ],
   "source": [
    "save_data(\"data/raw_pages.json\",content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
